import { GoogleGenerativeAI } from "@google/generative-ai";
import Conversation from '../models/Conversation.js';
import Session from '../models/Session.js';
import dotenv from 'dotenv';
import multer from 'multer';
import path from 'path';
import fs from 'fs';
import { fileURLToPath } from 'url';
import { createWorker } from 'tesseract.js';
import mammoth from 'mammoth';
import pdfParse from 'pdf-parse';
import { trackApiRequest, checkQuotaAvailable } from '../utils/quotaMonitor.js';
import { isVercel, isVercelPath } from '../utils/environmentHelper.js';

dotenv.config();

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Verificaci√≥n mejorada del entorno Vercel
const vercelEnvironment = isVercel() || process.cwd().includes('/var/task');
console.log(`ChatController - Entorno detectado: ${vercelEnvironment ? 'Vercel' : 'Desarrollo local'}`);
console.log(`ChatController - Directorio actual: ${process.cwd()}`);

// Crear el directorio de uploads si no existe (solo si no estamos en Vercel)
const uploadsDir = path.join(__dirname, '../uploads');
const tempDir = '/tmp';
if (!vercelEnvironment && !fs.existsSync(uploadsDir)) {
  try {
    fs.mkdirSync(uploadsDir, { recursive: true });
    console.log(`‚úÖ Directorio de uploads creado: ${uploadsDir}`);
  } catch (err) {
    console.error(`‚ùå Error creando directorio de uploads:`, err);
  }
}

// Configurar Gemini con manejo de errores mejorado
let genAI;
try {
  const apiKey = process.env.GEMINI_API_KEY;
  if (!apiKey) {
    console.error('‚ö†Ô∏è Error: La variable de entorno GEMINI_API_KEY no est√° definida');
    console.log('üìù Aseg√∫rate de crear un archivo .env con tu clave API de Gemini');
  } else {
    genAI = new GoogleGenerativeAI(apiKey);
    console.log('‚úÖ Gemini AI configurado correctamente');
  }
} catch (error) {
  console.error('‚ùå Error al inicializar Gemini:', error);
}

// Almacena las sesiones de chat activas
const activeSessions = new Map();

// Gesti√≥n de l√≠mites de tasa para Gemini API
const rateLimiter = {
  queue: [],
  processing: false,
  lastRequestTime: 0,
  minTimeBetweenRequests: 30000, // 30 segundos entre solicitudes
  maxRetries: 3,
  
  // A√±adir solicitud a la cola
  addToQueue: function(promiseFunction, retryCount = 0) {
    return new Promise((resolve, reject) => {
      this.queue.push({
        promiseFunction,
        resolve,
        reject,
        retryCount
      });
      
      if (!this.processing) {
        this.processQueue();
      }
    });
  },
  
  // Procesar la cola de solicitudes
  processQueue: async function() {
    if (this.queue.length === 0) {
      this.processing = false;
      return;
    }
    
    this.processing = true;
    const { promiseFunction, resolve, reject, retryCount } = this.queue.shift();
    
    // Calcular el tiempo de espera necesario
    const currentTime = Date.now();
    const timeToWait = Math.max(0, this.lastRequestTime + this.minTimeBetweenRequests - currentTime);
    
    if (timeToWait > 0) {
      console.log(`Esperando ${timeToWait}ms antes de la siguiente solicitud`);
      await new Promise(r => setTimeout(r, timeToWait));
    }
    
    try {
      this.lastRequestTime = Date.now();
      const result = await promiseFunction();
      resolve(result);
    } catch (error) {
      console.error('Error en solicitud a Gemini API:', error);
      
      // Comprobar si es un error de l√≠mite de tasa
      if (error.message && error.message.includes('429 Too Many Requests')) {
        let retryDelay = 30000; // Por defecto 30 segundos
        
        // Extraer el tiempo de espera sugerido por la API si est√° disponible
        const retryDelayMatch = error.message.match(/retryDelay:"(\d+)s"/);
        if (retryDelayMatch && retryDelayMatch[1]) {
          retryDelay = parseInt(retryDelayMatch[1]) * 1000;
        }
        
        // A√±adir backoff exponencial
        retryDelay = retryDelay * Math.pow(2, retryCount);
        
        if (retryCount < this.maxRetries) {
          console.log(`Reintento ${retryCount + 1}/${this.maxRetries} despu√©s de ${retryDelay/1000}s`);
          
          // Esperar y reintentar
          setTimeout(() => {
            this.addToQueue(promiseFunction, retryCount + 1)
              .then(resolve)
              .catch(reject);
          }, retryDelay);
        } else {
          reject(new Error('Se alcanz√≥ el n√∫mero m√°ximo de reintentos debido a l√≠mites de tasa'));
        }
      } else {
        reject(error);
      }
    }
    
    // Procesar la siguiente solicitud en la cola
    setTimeout(() => this.processQueue(), 100);
  }
};

// Funci√≥n para extraer texto de diferentes tipos de documentos
const extractTextFromDocument = async (filePath, fileType) => {
  try {
    console.log(`Verificando existencia de archivo en: ${filePath}`);
    
    // Verificar si estamos en Vercel y el archivo no est√° en /tmp
    if ((vercelEnvironment || isVercelPath(filePath)) && !filePath.startsWith('/tmp')) {
      console.log(`Ruta de archivo incompatible con Vercel: ${filePath}`);
      throw new Error(`Ruta de archivo no accesible en este entorno. Por favor use el campo de tema o texto.`);
    }
    
    // Verificar que el archivo existe
    if (!fs.existsSync(filePath)) {
      console.error(`Archivo no encontrado en: ${filePath}`);
      throw new Error(`El archivo no existe en la ruta especificada. Verifique que la ruta es correcta.`);
    }
    
    console.log(`Archivo encontrado, procediendo a extraer texto...`);

    if (fileType === 'application/pdf') {
      // Extraer texto de PDF
      try {
        const dataBuffer = fs.readFileSync(filePath);
        const pdfData = await pdfParse(dataBuffer);
        console.log(`PDF procesado: ${pdfData.text.length} caracteres extra√≠dos`);
        return pdfData.text;
      } catch (pdfError) {
        console.error('Error al procesar PDF:', pdfError);
        throw new Error('No se pudo extraer texto del PDF. Formato no compatible o documento corrupto.');
      }
    } else if (fileType === 'application/vnd.openxmlformats-officedocument.wordprocessingml.document' || 
               fileType === 'application/msword') {
      // Extraer texto de Word
      try {
        const dataBuffer = fs.readFileSync(filePath);
        const result = await mammoth.extractRawText({ buffer: dataBuffer });
        console.log(`Documento Word procesado: ${result.value.length} caracteres extra√≠dos`);
        return result.value;
      } catch (wordError) {
        console.error('Error al procesar documento Word:', wordError);
        throw new Error('No se pudo extraer texto del documento Word. Formato no compatible o documento corrupto.');
      }
    } else if (fileType.startsWith('image/')) {
      // Extraer texto de im√°genes usando OCR
      try {
        const worker = await createWorker();
        await worker.loadLanguage('spa');
        await worker.initialize('spa');
        const { data } = await worker.recognize(filePath);
        await worker.terminate();
        console.log(`Imagen procesada con OCR: ${data.text.length} caracteres extra√≠dos`);
        return data.text;
      } catch (ocrError) {
        console.error('Error al procesar imagen con OCR:', ocrError);
        throw new Error('No se pudo extraer texto de la imagen. Formato no compatible o imagen corrupta.');
      }
    }
    return '';
  } catch (error) {
    console.error('Error al extraer texto del documento:', error);
    throw new Error(`No se pudo procesar el documento: ${error.message}`);
  } finally {
    try {
      if (fs.existsSync(filePath)) {
        console.log(`Intentando eliminar archivo temporal: ${filePath}`);
        fs.unlinkSync(filePath);
        console.log(`Archivo temporal eliminado: ${filePath}`);
      }
    } catch (cleanupError) {
      console.error('Error al limpiar archivo temporal:', cleanupError);
    }
  }
};

// Funci√≥n para crear respuestas predefinidas para preguntas tipo multiple-choice y true-false
const getLocalAnswerValidation = (questionType, userAnswer, correctAnswer, explanation) => {
  let isCorrect;
  
  // Corregir la comparaci√≥n para preguntas verdadero/falso
  if (questionType === 'true-false') {
    // Normalizar la respuesta del usuario y la respuesta correcta
    const normalizedUserAnswer = userAnswer.toLowerCase() === 'true';
    const normalizedCorrectAnswer = correctAnswer === 'true' || correctAnswer === true;
    isCorrect = normalizedUserAnswer === normalizedCorrectAnswer;
  } else {
    // Para otros tipos de preguntas, comparaci√≥n directa
    isCorrect = userAnswer === correctAnswer;
  }
  
  if (questionType === 'multiple-choice') {
    return {
      isCorrect,
      feedback: isCorrect 
        ? `¬°Correcto! üëè ${explanation || 'Muy bien hecho.'}` 
        : `Incorrecto. üòï La respuesta correcta es ${correctAnswer}. ${explanation || 'Intenta de nuevo.'}`
    };
  } else if (questionType === 'true-false') {
    return {
      isCorrect,
      feedback: isCorrect 
        ? `¬°Correcto! üëè ${explanation || 'Bien hecho.'}` 
        : `Incorrecto. üòï La respuesta correcta es ${correctAnswer === 'true' || correctAnswer === true ? 'Verdadero' : 'Falso'}. ${explanation || 'Intenta de nuevo.'}`
    };
  }
};

// Generar cuestionario basado en el contenido
export const generateQuiz = async (req, res) => {
  try {
    const { topic, questionType, questionCount, sessionId, documentContent } = req.body;
    
    if (!genAI) {
      return res.status(500).json({ 
        error: 'No se ha configurado correctamente la API de Gemini',
        message: 'Error interno del servidor: API key de Gemini no configurada. Verifica el archivo .env'
      });
    }
    
    let content = documentContent || '';
    let prompt = '';
    let currentSessionId = sessionId;
    let sessionTitle = topic || 'Cuestionario sin t√≠tulo';
    
    // Si hay un documento subido, procesarlo
    if (req.file) {
      const filePath = req.file.path;
      const fileType = req.file.mimetype;
      
      // Verificar si la ruta es v√°lida para el entorno actual
      const isVercelEnv = vercelEnvironment || isVercelPath(filePath);
      if (isVercelEnv && !filePath.startsWith('/tmp')) {
        console.log(`Detectada ruta incompatible con Vercel: ${filePath}`);
        return res.status(400).json({ 
          error: "La carga de archivos no est√° disponible en este entorno. Por favor, utilice el campo de tema o texto."
        });
      }
      
      console.log(`Documento subido:`, {
        filePath,
        fileType,
        exists: fs.existsSync(filePath),
        isVercelEnv
      });
      
      try {
        console.log(`Procesando documento: ${filePath} (${fileType})`);
        content = await extractTextFromDocument(filePath, fileType);
        console.log(`Texto extra√≠do exitosamente (${content.length} caracteres)`);
      } catch (error) {
        console.error('Error procesando el documento:', error);
        return res.status(400).json({ error: error.message });
      }
    }
    
    const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
    
    // Verificar cuota antes de generar
    const quotaStatus = checkQuotaAvailable();
    
    if (quotaStatus.isQuotaExceeded) {
      console.log(`Cuota de API excedida. Tiempo estimado para reinicio: ${Math.ceil(quotaStatus.timeToReset/1000)}s`);
      return res.status(429).json({ 
        error: 'La API est√° experimentando alta demanda',
        message: `Por favor, intenta de nuevo en ${Math.ceil(quotaStatus.timeToReset/1000)} segundos`,
        retryAfter: Math.ceil(quotaStatus.timeToReset/1000)
      });
    }
    
    // Registrar el uso de la API
    trackApiRequest();
    
    // Construir el prompt seg√∫n el tipo de cuestionario
    if (questionType === 'multiple-choice') {
      prompt = `Act√∫a como un profesor que crea un cuestionario de opci√≥n m√∫ltiple sobre "${topic}". 
      ${content ? 'Bas√°ndote en el siguiente contenido: ' + content.substring(0, 5000) : ''}
      Genera ${questionCount || 5} preguntas de opci√≥n m√∫ltiple con 4 opciones cada una (a, b, c, d). 
      Para cada pregunta, marca claramente la respuesta correcta y proporciona una explicaci√≥n de por qu√© es correcta.
      Usa emojis para hacer el contenido m√°s atractivo.
      Formatea tu respuesta como un objeto JSON con esta estructura exacta:
      {
        "questions": [
          {
            "question": "¬øPregunta 1?",
            "options": ["opci√≥n a", "opci√≥n b", "opci√≥n c", "opci√≥n d"],
            "correctAnswer": "a",
            "explanation": "Explicaci√≥n de por qu√© esta respuesta es correcta"
          }
        ]
      }`;
    } else if (questionType === 'true-false') {
      prompt = `Act√∫a como un profesor que crea un cuestionario de verdadero/falso sobre "${topic}". 
      ${content ? 'Bas√°ndote en el siguiente contenido: ' + content.substring(0, 5000) : ''}
      Genera ${questionCount || 5} afirmaciones y especifica si cada una es verdadera o falsa.
      Para cada afirmaci√≥n, proporciona una explicaci√≥n de por qu√© es verdadera o falsa.
      Usa emojis para hacer el contenido m√°s atractivo.
      Formatea tu respuesta como un objeto JSON con esta estructura exacta:
      {
        "questions": [
          {
            "statement": "Afirmaci√≥n 1",
            "isTrue": true/false,
            "explanation": "Explicaci√≥n de por qu√© esta afirmaci√≥n es verdadera/falsa"
          }
        ]
      }`;
    } else { // open-ended
      prompt = `Act√∫a como un profesor que crea un cuestionario de preguntas abiertas sobre "${topic}". 
      ${content ? 'Bas√°ndote en el siguiente contenido: ' + content.substring(0, 5000) : ''}
      Genera ${questionCount || 5} preguntas que requieran respuestas explicativas.
      Para cada pregunta, proporciona una respuesta modelo que sea completa y detallada.
      Usa emojis para hacer el contenido m√°s atractivo.
      Formatea tu respuesta como un objeto JSON con esta estructura exacta:
      {
        "questions": [
          {
            "question": "¬øPregunta 1?",
            "modelAnswer": "Respuesta modelo detallada para esta pregunta"
          }
        ]
      }`;
    }
    
    // Crear una nueva sesi√≥n en la BD si es necesario
    if (!sessionId) {
      const newSession = new Session({
        title: sessionTitle,
        type: 'quiz',
        questionType: questionType,
        topic: topic,
        createdAt: new Date()
      });
      
      const savedSession = await newSession.save();
      currentSessionId = savedSession._id.toString();
    }
    
    // Generar el cuestionario con Gemini usando el rate limiter
    const generateQuizContent = async () => {
      const result = await model.generateContent(prompt);
      return result.response.text();
    };
    
    const response = await rateLimiter.addToQueue(generateQuizContent);
    
    // Intentar parsear la respuesta como JSON
    let parsedResponse;
    try {
      // Extraer el JSON de la respuesta (por si Gemini a√±ade texto adicional)
      const jsonMatch = response.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        parsedResponse = JSON.parse(jsonMatch[0]);
      } else {
        throw new Error('No se encontr√≥ un formato JSON v√°lido en la respuesta');
      }
    } catch (error) {
      console.error('Error al parsear la respuesta JSON:', error);
      // Si hay error al parsear, devolvemos la respuesta como texto
      parsedResponse = { 
        raw: response,
        error: 'No se pudo generar un cuestionario estructurado. Por favor, intente de nuevo.'
      };
    }
    
    // Guardar el cuestionario en la base de datos
    const conversation = new Conversation({
      sessionId: currentSessionId,
      prompt: JSON.stringify({
        topic,
        questionType,
        questionCount,
        hasDocument: !!req.file
      }),
      response: JSON.stringify(parsedResponse),
      timestamp: new Date()
    });
    
    await conversation.save();
    
    res.json({
      sessionId: currentSessionId,
      sessionTitle,
      quiz: parsedResponse
    });
  } catch (error) {
    console.error('Error al generar el cuestionario:', error);
    res.status(500).json({ 
      error: 'Error al procesar la solicitud',
      details: error.message 
    });
  }
};

// Validar respuesta del usuario
export const validateAnswer = async (req, res) => {
  try {
    const { sessionId, questionIndex, userAnswer, question, correctAnswer, questionType } = req.body;
    
    if (!genAI) {
      return res.status(500).json({ 
        error: 'No se ha configurado correctamente la API de Gemini',
        message: 'Error interno del servidor: API key de Gemini no configurada. Verifica el archivo .env'
      });
    }
    
    // Para preguntas de opci√≥n m√∫ltiple o verdadero/falso, la validaci√≥n es directa
    if (correctAnswer !== undefined) {
      let isCorrect;
      
      // Corregir la comparaci√≥n para preguntas verdadero/falso
      if (questionType === 'true-false') {
        // Normalizar valores para la comparaci√≥n
        const normalizedUserAnswer = userAnswer.toLowerCase() === 'true';
        const normalizedCorrectAnswer = correctAnswer === 'true' || correctAnswer === true;
        isCorrect = normalizedUserAnswer === normalizedCorrectAnswer;
      } else {
        // Para otras preguntas, comparaci√≥n directa
        isCorrect = userAnswer === correctAnswer;
      }
      
      // Usar validaci√≥n local con la comparaci√≥n corregida
      const result = getLocalAnswerValidation(
        questionType, 
        userAnswer, 
        correctAnswer, 
        question.explanation
      );
      
      // Guardar la respuesta del usuario en la base de datos
      await Conversation.findOneAndUpdate(
        { sessionId },
        { 
          $push: { 
            userAnswers: {
              questionIndex,
              userAnswer,
              correct: isCorrect
            }
          }
        }
      );
      
      return res.json(result);
    }
    
    // Para preguntas abiertas, verificar cuota antes de usar Gemini
    const quotaStatus = checkQuotaAvailable();
    
    // Si la cuota est√° excedida, usar evaluaci√≥n local
    if (quotaStatus.isQuotaExceeded) {
      console.log(`Cuota de API excedida. Tiempo estimado para reinicio: ${Math.ceil(quotaStatus.timeToReset/1000)}s`);
      
      // Crear una respuesta gen√©rica para preguntas abiertas
      const fallbackResponse = {
        isCorrect: null,
        score: 5,
        feedback: "El sistema est√° experimentando alta demanda. No podemos evaluar tu respuesta detalladamente en este momento. Por favor, compara tu respuesta con la respuesta modelo proporcionada. üß†"
      };
      
      // Guardar en la base de datos
      await Conversation.findOneAndUpdate(
        { sessionId },
        { 
          $push: { 
            userAnswers: {
              questionIndex,
              userAnswer,
              correct: null,
              score: 5
            }
          }
        }
      );
      
      return res.json(fallbackResponse);
    }
    
    // Registrar el uso de la API
    trackApiRequest();
    
    // Para preguntas abiertas, usar Gemini con gesti√≥n de l√≠mites de tasa
    const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
    
    const prompt = `Act√∫a como un profesor que eval√∫a respuestas a preguntas abiertas.
    
    La pregunta es: "${question.question}"
    
    La respuesta modelo es: "${question.modelAnswer}"
    
    La respuesta del estudiante es: "${userAnswer}"
    
    Eval√∫a si la respuesta del estudiante cubre los puntos clave de la respuesta modelo.
    No es necesario que sea exactamente igual, pero debe mostrar comprensi√≥n del tema.
    Utiliza emojis para hacer m√°s amigable tu feedback.
    
    Formatea tu respuesta como un objeto JSON con esta estructura:
    {
      "isCorrect": true/false,
      "score": (un n√∫mero del 0 al 10),
      "feedback": "Explicaci√≥n detallada para el estudiante, comentando lo que est√° bien y lo que podr√≠a mejorar"
    }`;
    
    const generateResponse = async () => {
      const result = await model.generateContent(prompt);
      return result.response.text();
    };
    
    // Usar el rate limiter para la solicitud
    const response = await rateLimiter.addToQueue(generateResponse);
    
    // Intentar parsear la respuesta como JSON
    try {
      const jsonMatch = response.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const evaluation = JSON.parse(jsonMatch[0]);
        
        // Guardar la respuesta del usuario en la base de datos
        await Conversation.findOneAndUpdate(
          { sessionId },
          { 
            $push: { 
              userAnswers: {
                questionIndex,
                userAnswer,
                correct: evaluation.isCorrect,
                score: evaluation.score
              }
            }
          }
        );
        
        return res.json(evaluation);
      } else {
        // Si no podemos obtener un JSON v√°lido, crear una respuesta gen√©rica
        const fallbackResponse = {
          isCorrect: null,
          score: 5,
          feedback: "No se pudo evaluar con precisi√≥n tu respuesta. Sin embargo, recuerda que lo importante es que hayas comprendido el concepto. Revisa la respuesta modelo a continuaci√≥n. üß†"
        };
        
        return res.json(fallbackResponse);
      }
    } catch (error) {
      console.error('Error al evaluar la respuesta:', error);
      
      // Si hay un error al parsear o procesar, enviamos una respuesta fallback
      return res.json({
        isCorrect: null,
        score: 5,
        feedback: "Debido a problemas t√©cnicos, no podemos evaluar detalladamente tu respuesta en este momento. Por favor, compara tu respuesta con la respuesta modelo para autoevaluarte. üîç"
      });
    }
  } catch (error) {
    console.error('Error al validar la respuesta:', error);
    res.status(500).json({ 
      error: 'Error al procesar la solicitud',
      details: error.message,
      fallbackResponse: {
        isCorrect: null,
        score: 5,
        feedback: "Debido a problemas t√©cnicos, no podemos evaluar tu respuesta en este momento. Por favor, intenta de nuevo m√°s tarde. üïí"
      }
    });
  }
};

// Obtener historial de conversaciones de una sesi√≥n espec√≠fica
export const getConversationHistory = async (req, res) => {
  try {
    const { sessionId } = req.query;
    
    if (!sessionId) {
      return res.status(400).json({ error: 'Se requiere ID de sesi√≥n' });
    }
    
    const conversations = await Conversation.find({ sessionId })
      .sort({ timestamp: 1 })
      .exec();
      
    res.json(conversations);
  } catch (error) {
    console.error('Error al obtener el historial:', error);
    res.status(500).json({ error: 'Error al obtener el historial de conversaciones' });
  }
};

// Obtener todas las sesiones disponibles
export const getSessions = async (req, res) => {
  try {
    const sessions = await Session.find()
      .sort({ createdAt: -1 }) // Ordenar por m√°s reciente primero
      .limit(20) // Limitar a las 20 sesiones m√°s recientes
      .exec();
      
    res.json(sessions);
  } catch (error) {
    console.error('Error al obtener las sesiones:', error);
    res.status(500).json({ error: 'Error al obtener las sesiones de chat' });
  }
};

// Eliminar una sesi√≥n
export const deleteSession = async (req, res) => {
  try {
    const { sessionId } = req.params;
    
    if (!sessionId) {
      return res.status(400).json({ error: 'Se requiere ID de sesi√≥n' });
    }
    
    // Eliminar la sesi√≥n y sus conversaciones
    await Session.findByIdAndDelete(sessionId);
    await Conversation.deleteMany({ sessionId });
    
    // Eliminar del mapa de sesiones activas si existe
    if (activeSessions.has(sessionId)) {
      activeSessions.delete(sessionId);
    }
    
    res.json({ success: true, message: 'Sesi√≥n eliminada correctamente' });
  } catch (error) {
    console.error('Error al eliminar la sesi√≥n:', error);
    res.status(500).json({ error: 'Error al eliminar la sesi√≥n de chat' });
  }
};
